{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxv6Mt7yglQfNx+Ma3K3Dn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarthiBorkar/VisionGuard/blob/main/VisionGuard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okqYfVmTouhh"
      },
      "outputs": [],
      "source": []
    },
    {
      "source": [
        "# Import the necessary libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "KrDi92e0o3Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Import necessary libraries\n",
        "import cv2\n",
        "\n",
        "# Load the pre-trained Haar cascades for human, animal, and object detection\n",
        "human_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_fullbody.xml')\n",
        "animal_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_animal.xml')\n",
        "object_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_object.xml')\n",
        "\n",
        "# Function to detect humans, animals, and objects in an image\n",
        "def detect(image):\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect humans, animals, and objects\n",
        "    humans = human_cascade.detectMultiScale(gray, 1.1, 3)\n",
        "    animals = animal_cascade.detectMultiScale(gray, 1.1, 3)\n",
        "    objects = object_cascade.detectMultiScale(gray, 1.1, 3)\n",
        "\n",
        "    # Draw rectangles around the detected objects\n",
        "    for (x, y, w, h) in humans:\n",
        "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "    for (x, y, w, h) in animals:\n",
        "        cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "    for (x, y, w, h) in objects:\n",
        "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
        "\n",
        "    # Show the image with detected objects\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "\n",
        "# Function to detect humans, animals, and objects in a video\n",
        "def detect_video(video_path):\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        # Read a frame from the video\n",
        "        ret, frame = cap.read()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "TT92cFyGptub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def resize_image():\n",
        "    img = cv2.imread(\"note.jpg\")\n",
        "    resized_image = cv2.resize(img, (30, 60))\n",
        "    cv2.imwrite(\"note2.jpg\",resized_image)\n",
        "def store_raw_images():\n",
        "    neg_images_link = 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n00523513'\n",
        "    neg_image_urls = urllib.request.urlopen(neg_images_link).read().decode()\n",
        "    pic_num = 1\n",
        "\n",
        "    if not os.path.exists('neg'):\n",
        "        os.makedirs('neg')\n",
        "\n",
        "    for i in neg_image_urls.split('\\n'):\n",
        "        try:\n",
        "            print(i)\n",
        "            urllib.request.urlretrieve(i, \"neg/\"+str(pic_num)+\".jpg\")\n",
        "            img = cv2.imread(\"neg/\"+str(pic_num)+\".jpg\",cv2.IMREAD_GRAYSCALE)\n",
        "            # should be larger than samples / pos pic (so we can place our image on it)\n",
        "            resized_image = cv2.resize(img, (100, 100))\n",
        "            cv2.imwrite(\"neg/\"+str(pic_num)+\".jpg\",resized_image)\n",
        "            pic_num += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "\n",
        "def find_uglies():\n",
        "    match = False\n",
        "    for file_type in ['neg']:\n",
        "        for img in os.listdir(file_type):\n",
        "            for ugly in os.listdir('uglies'):\n",
        "                try:\n",
        "                    current_image_path = str(file_type)+'/'+str(img)\n",
        "                    ugly = cv2.imread('uglies/'+str(ugly))\n",
        "                    question = cv2.imread(current_image_path)\n",
        "                    if ugly.shape == question.shape and not(np.bitwise_xor(ugly,question).any()):\n",
        "                        print('That is one ugly pic! Deleting!')\n",
        "                        print(current_image_path)\n",
        "                        os.remove(current_image_path)\n",
        "                except Exception as e:\n",
        "                    print(str(e))\n",
        "def create_pos_n_neg():\n",
        "    for file_type in ['neg']:\n",
        "        for img in os.listdir(file_type):\n",
        "            if file_type == 'pos':\n",
        "                line = file_type+'/'+img+' 1 0 0 50 50\\n'\n",
        "                with open('info.dat','a') as f:\n",
        "                    f.write(line)\n",
        "            elif file_type == 'neg':\n",
        "                line = file_type+'/'+img+'\\n'\n",
        "                with open('bg.txt','a') as f:\n",
        "                    f.write(line)\n",
        "\n",
        "\n",
        "create_pos_n_neg()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "MLMjxpA1puSc",
        "outputId": "d7ddcca8-83d1-47c9-92a0-4aa9f1b61bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'neg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-db7964240dd3>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mcreate_pos_n_neg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-db7964240dd3>\u001b[0m in \u001b[0;36mcreate_pos_n_neg\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_pos_n_neg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'neg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfile_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_type\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' 1 0 0 50 50\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'neg'"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install opencv-python\n",
        "import urllib.request\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def resize_image():\n",
        "    img = cv2.imread(\"note.jpg\")\n",
        "    resized_image = cv2.resize(img, (30, 60))\n",
        "    cv2.imwrite(\"note2.jpg\",resized_image)\n",
        "def store_raw_images():\n",
        "    neg_images_link = 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n00523513'\n",
        "    neg_image_urls = urllib.request.urlopen(neg_images_link).read().decode()\n",
        "    pic_num = 1\n",
        "\n",
        "    if not os.path.exists('neg'):\n",
        "        os.makedirs('neg')\n",
        "\n",
        "    for i in neg_image_urls.split('\\n'):\n",
        "        try:\n",
        "            print(i)\n",
        "            urllib.request.urlretrieve(i, \"neg/\"+str(pic_num)+\".jpg\")\n",
        "            img = cv2.imread(\"neg/\"+str(pic_num)+\".jpg\",cv2.IMREAD_GRAYSCALE)\n",
        "            # should be larger than samples / pos pic (so we can place our image on it)\n",
        "            resized_image = cv2.resize(img, (100, 100))\n",
        "            cv2.imwrite(\"neg/\"+str(pic_num)+\".jpg\",resized_image)\n",
        "            pic_num += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "\n",
        "def find_uglies():\n",
        "    match = False\n",
        "    for file_type in ['neg']:\n",
        "        for img in os.listdir(file_type):\n",
        "            for ugly in os.listdir('uglies'):\n",
        "                try:\n",
        "                    current_image_path = str(file_type)+'/'+str(img)\n",
        "                    ugly = cv2.imread('uglies/'+str(ugly))\n",
        "                    question = cv2.imread(current_image_path)\n",
        "                    if ugly.shape == question.shape and not(np.bitwise_xor(ugly,question).any()):\n",
        "print('That is one ugly pic! Deleting!')\n",
        "print(current_image_path)\n",
        "os.remove(current_image_path)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "we0gXONfPatN",
        "outputId": "f1857abb-2fe1-4486-d681-1b80cec7bed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'if' statement on line 41 (<ipython-input-8-44a257cff93b>, line 42)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-44a257cff93b>\"\u001b[0;36m, line \u001b[0;32m42\u001b[0m\n\u001b[0;31m    print('That is one ugly pic! Deleting!')\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KMXg80ZbPBpl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}